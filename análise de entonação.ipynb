{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f686250a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting resampy\n",
      "  Downloading resampy-0.4.2-py3-none-any.whl (3.1 MB)\n",
      "                                              0.0/3.1 MB ? eta -:--:--\n",
      "     ------                                   0.5/3.1 MB 15.9 MB/s eta 0:00:01\n",
      "     ----------------                         1.3/3.1 MB 16.0 MB/s eta 0:00:01\n",
      "     ----------------------------             2.2/3.1 MB 17.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  3.1/3.1 MB 17.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  3.1/3.1 MB 17.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.1/3.1 MB 12.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\victor\\anaconda3\\lib\\site-packages (from resampy) (1.24.3)\n",
      "Requirement already satisfied: numba>=0.53 in c:\\users\\victor\\anaconda3\\lib\\site-packages (from resampy) (0.57.0)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in c:\\users\\victor\\anaconda3\\lib\\site-packages (from numba>=0.53->resampy) (0.40.0)\n",
      "Installing collected packages: resampy\n",
      "Successfully installed resampy-0.4.2\n"
     ]
    }
   ],
   "source": [
    "# pip install librosa scikit-learn\n",
    "# !pip install keras\n",
    "# !pip install tensorflow\n",
    "# !pip install scikeras\n",
    "# !pip install resampy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ca63d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo: 63.64%\n"
     ]
    }
   ],
   "source": [
    "#MODELO 1\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "\n",
    "\n",
    "# Carregar os dados de áudio e extrair características\n",
    "def extract_features(file_path):\n",
    "    y, sr = librosa.load(file_path)\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13), axis=1)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(y=y, sr=sr), axis=1)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y=y, sr=sr), axis=1)\n",
    "    features = np.hstack([mfccs, chroma, mel])\n",
    "    return features\n",
    "\n",
    "# Diretório onde os arquivos de áudio estão armazenados\n",
    "audio_directory = \"audios classificados/\"\n",
    "\n",
    "# Lista de arquivos de áudio e seus rótulos\n",
    "audio_files = []\n",
    "labels = []\n",
    "\n",
    "for filename in os.listdir(audio_directory):\n",
    "    if filename.endswith(\".wav\"):  # Certifique-se de que são arquivos de áudio\n",
    "        # Extrair o rótulo do nome do arquivo\n",
    "        label = 1 if \"positivo\" in filename.lower() else 0\n",
    "\n",
    "        # Adicionar o arquivo e o rótulo às listas\n",
    "        audio_files.append(os.path.join(audio_directory, filename))\n",
    "        labels.append(label)\n",
    "\n",
    "# Extrair características de cada áudio\n",
    "X = np.array([extract_features(file) for file in audio_files])\n",
    "y = np.array(labels)\n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Construir e treinar o modelo\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar o modelo\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Acurácia do modelo: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53236a29",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7722 - accuracy: 0.5517 - val_loss: 0.8094 - val_accuracy: 0.3750\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6493 - accuracy: 0.6552 - val_loss: 0.7936 - val_accuracy: 0.3750\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5576 - accuracy: 0.8276 - val_loss: 0.7800 - val_accuracy: 0.6250\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4927 - accuracy: 0.8276 - val_loss: 0.7699 - val_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4432 - accuracy: 0.9310 - val_loss: 0.7628 - val_accuracy: 0.3750\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4056 - accuracy: 0.9655 - val_loss: 0.7569 - val_accuracy: 0.3750\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3741 - accuracy: 0.9655 - val_loss: 0.7520 - val_accuracy: 0.3750\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3471 - accuracy: 0.9655 - val_loss: 0.7467 - val_accuracy: 0.3750\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3231 - accuracy: 1.0000 - val_loss: 0.7418 - val_accuracy: 0.3750\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3017 - accuracy: 1.0000 - val_loss: 0.7380 - val_accuracy: 0.3750\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.7740 - accuracy: 0.4706\n",
      "Acurácia do modelo: 47.06%\n"
     ]
    }
   ],
   "source": [
    "#MODELO 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "\n",
    "# Diretório onde os arquivos de áudio estão armazenados\n",
    "audio_directory = \"audios classificados/\"\n",
    "\n",
    "# Lista de arquivos de áudio e seus rótulos\n",
    "audio_files = []\n",
    "labels = []\n",
    "\n",
    "for filename in os.listdir(audio_directory):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        label = 1 if \"positivo\" in filename.lower() else 0\n",
    "        audio_files.append(os.path.join(audio_directory, filename))\n",
    "        labels.append(label)\n",
    "\n",
    "# Extrair características de áudio\n",
    "def extract_features(file_path):\n",
    "    y, sr = librosa.load(file_path)\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13), axis=1)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(y=y, sr=sr), axis=1)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y=y, sr=sr), axis=1)\n",
    "    features = np.hstack([mfccs, chroma, mel])\n",
    "    return features\n",
    "\n",
    "# Extrair características de todos os áudios\n",
    "X = np.array([extract_features(file) for file in audio_files])\n",
    "y = np.array(labels)\n",
    "\n",
    "# Normalizar os dados\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)#, random_state=42)\n",
    "\n",
    "# Construir modelo de rede neural\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Camada de saída com ativação sigmoid para retornar um valor entre 0 e 1\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinar o modelo\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Avaliar o modelo\n",
    "accuracy = model.evaluate(X_test, y_test)[1]\n",
    "print(f'Acurácia do modelo: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60ff80a4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Victor\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "54 fits failed out of a total of 108.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Victor\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Victor\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1491, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Victor\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 760, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Victor\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 926, in _fit\n",
      "    self._check_model_compatibility(y)\n",
      "  File \"C:\\Users\\Victor\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 569, in _check_model_compatibility\n",
      "    raise ValueError(\n",
      "ValueError: loss=hinge but model compiled with binary_crossentropy. Data may not match loss function!\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Victor\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.62393162 0.59615385        nan        nan 0.59188034 0.51495726\n",
      "        nan        nan 0.54059829 0.51495726        nan        nan\n",
      " 0.70726496 0.56837607        nan        nan 0.56837607 0.62606838\n",
      "        nan        nan 0.56623932 0.48717949        nan        nan\n",
      " 0.56837607 0.5982906         nan        nan 0.51282051 0.56837607\n",
      "        nan        nan 0.45940171 0.48717949        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor Acurácia: 0.7072649572649573\n",
      "Melhores Parâmetros: {'batch_size': 64, 'epochs': 10, 'loss': 'binary_crossentropy', 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "#BUSCA DE HIPERPARÂMETROS\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from scikeras.wrappers import KerasClassifier \n",
    "import tensorflow as tf\n",
    "\n",
    "# Função que cria o modelo\n",
    "def create_model(optimizer='adam', loss='binary_crossentropy',\n",
    "                 batch_size=32, epochs=10, verbose=0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Utiliza a classe Adam do módulo tf.keras.optimizers.legacy\n",
    "    optimizer = tf.keras.optimizers.legacy.Adam() if optimizer == 'adam' else optimizer\n",
    "    \n",
    "    metrics = ['accuracy'] if loss != 'hinge' else ['accuracy', 'precision']\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    return model\n",
    "\n",
    "# Crie o modelo KerasClassifier para ser usado no GridSearchCV\n",
    "model = KerasClassifier(model=create_model, verbose=0)\n",
    "\n",
    "# Defina os parâmetros a serem testados\n",
    "param_grid = {\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'epochs': [10, 20, 30],\n",
    "    'optimizer': ['adam', 'rmsprop'],\n",
    "    'loss': ['binary_crossentropy', 'hinge']\n",
    "}\n",
    "\n",
    "# Crie o objeto GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=3)\n",
    "\n",
    "# Execute a busca\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Imprima os melhores resultados\n",
    "print(\"Melhor Acurácia:\", grid_result.best_score_)\n",
    "print(\"Melhores Parâmetros:\", grid_result.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "83e68164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 0.7146 - accuracy: 0.3514\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6204 - accuracy: 0.6486\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5485 - accuracy: 0.7838\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4920 - accuracy: 0.8919\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4452 - accuracy: 0.9189\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4056 - accuracy: 0.9459\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3718 - accuracy: 0.9459\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3429 - accuracy: 0.9459\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3171 - accuracy: 0.9189\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2950 - accuracy: 0.9189\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.8406 - accuracy: 0.4118\n",
      "Acurácia do modelo nos dados de teste: 0.4117647111415863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Victor\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "#MELHOR MODELO\n",
    "\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Diretório onde os arquivos de áudio estão armazenados\n",
    "audio_directory = \"audios classificados/\"\n",
    "\n",
    "# Lista de arquivos de áudio e seus rótulos\n",
    "audio_files = []\n",
    "labels = []\n",
    "\n",
    "for filename in os.listdir(audio_directory):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        label = 1 if \"positivo\" in filename.lower() else 0\n",
    "        audio_files.append(os.path.join(audio_directory, filename))\n",
    "        labels.append(label)\n",
    "\n",
    "# Extrair características de áudio\n",
    "def extract_features(file_path):\n",
    "    y, sr = librosa.load(file_path)\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13), axis=1)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(y=y, sr=sr), axis=1)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y=y, sr=sr), axis=1)\n",
    "    features = np.hstack([mfccs, chroma, mel])\n",
    "    return features\n",
    "\n",
    "# Extrair características de todos os áudios\n",
    "X = np.array([extract_features(file) for file in audio_files])\n",
    "y = np.array(labels)\n",
    "\n",
    "# Normalizar os dados\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)#, random_state=42)\n",
    "\n",
    "\n",
    "# Defina os melhores parâmetros encontrados na busca\n",
    "best_params = {'batch_size': 64, 'epochs': 10, 'loss': 'binary_crossentropy', 'optimizer': 'adam'}\n",
    "\n",
    "# Crie e compile o modelo com os melhores parâmetros\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = Adam() if best_params['optimizer'] == 'adam' else best_params['optimizer']\n",
    "model.compile(optimizer=optimizer, loss=best_params['loss'], metrics=['accuracy'])\n",
    "\n",
    "# Treine o modelo\n",
    "model.fit(X_train, y_train, batch_size=best_params['batch_size'], epochs=best_params['epochs'], verbose=1)\n",
    "\n",
    "# Avalie o modelo nos dados de teste\n",
    "accuracy = model.evaluate(X_test, y_test)[1]\n",
    "print(\"Acurácia do modelo nos dados de teste:\", accuracy)\n",
    "\n",
    "# Salve o modelo em um arquivo .h5\n",
    "model.save(\"seu_modelo.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "14982c6a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 55ms/step\n",
      "Arquivo: negativo - 1.wav, Score de Sentimento: 0.0020549313630908728\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Arquivo: negativo - 10.wav, Score de Sentimento: 0.000646142871119082\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Arquivo: negativo - 11.wav, Score de Sentimento: 0.005195104517042637\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Arquivo: negativo - 12.wav, Score de Sentimento: 0.9985334873199463\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Arquivo: negativo - 13.wav, Score de Sentimento: 1.9160440842824755e-06\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Arquivo: negativo - 14.wav, Score de Sentimento: 0.9999302625656128\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Arquivo: negativo - 15.wav, Score de Sentimento: 0.9999697804450989\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Arquivo: negativo - 16.wav, Score de Sentimento: 0.0035558121744543314\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Arquivo: negativo - 17.wav, Score de Sentimento: 0.9999555349349976\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Arquivo: negativo - 18.wav, Score de Sentimento: 2.1862424759433452e-08\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Arquivo: negativo - 19.wav, Score de Sentimento: 0.9999980926513672\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Arquivo: negativo - 2.wav, Score de Sentimento: 0.0012724651023745537\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Arquivo: negativo - 20.wav, Score de Sentimento: 0.9933269619941711\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Arquivo: negativo - 21.wav, Score de Sentimento: 0.9748835563659668\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Arquivo: negativo - 22.wav, Score de Sentimento: 0.9999979734420776\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Arquivo: negativo - 23.wav, Score de Sentimento: 0.8482640981674194\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Arquivo: negativo - 24.wav, Score de Sentimento: 0.3652114272117615\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Arquivo: negativo - 25.wav, Score de Sentimento: 0.40039706230163574\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Arquivo: negativo - 26.wav, Score de Sentimento: 0.021012727171182632\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Arquivo: negativo - 27.wav, Score de Sentimento: 0.9996567964553833\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Arquivo: negativo - 3.wav, Score de Sentimento: 2.884068450725863e-08\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Arquivo: negativo - 4.wav, Score de Sentimento: 0.007431505713611841\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Arquivo: negativo - 5.wav, Score de Sentimento: 0.9999511241912842\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Arquivo: negativo - 6.wav, Score de Sentimento: 0.22485163807868958\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Arquivo: negativo - 7.wav, Score de Sentimento: 0.29085615277290344\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Arquivo: negativo - 8.wav, Score de Sentimento: 1.7216549019760663e-10\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Arquivo: negativo - 9.wav, Score de Sentimento: 6.750258762622252e-06\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Arquivo: positivo - 1.wav, Score de Sentimento: 0.999933123588562\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Arquivo: positivo - 10.wav, Score de Sentimento: 0.0265874732285738\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Arquivo: positivo - 11.wav, Score de Sentimento: 0.9997313022613525\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Arquivo: positivo - 12.wav, Score de Sentimento: 1.0890335033764131e-06\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Arquivo: positivo - 13.wav, Score de Sentimento: 0.9998711943626404\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Arquivo: positivo - 14.wav, Score de Sentimento: 0.9976471662521362\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Arquivo: positivo - 15.wav, Score de Sentimento: 0.9580974578857422\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Arquivo: positivo - 16.wav, Score de Sentimento: 0.9001957178115845\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Arquivo: positivo - 17.wav, Score de Sentimento: 0.999896764755249\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Arquivo: positivo - 18.wav, Score de Sentimento: 0.9811865091323853\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Arquivo: positivo - 19.wav, Score de Sentimento: 0.961373507976532\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Arquivo: positivo - 2.wav, Score de Sentimento: 0.9990456104278564\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Arquivo: positivo - 20.wav, Score de Sentimento: 0.5145277380943298\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Arquivo: positivo - 21.wav, Score de Sentimento: 0.00019911704293917865\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Arquivo: positivo - 22.wav, Score de Sentimento: 0.8375293016433716\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Arquivo: positivo - 23.wav, Score de Sentimento: 0.8920298218727112\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Arquivo: positivo - 24.wav, Score de Sentimento: 0.681489109992981\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Arquivo: positivo - 25.wav, Score de Sentimento: 4.5097032852936536e-05\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Arquivo: positivo - 26.wav, Score de Sentimento: 0.9973078370094299\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Arquivo: positivo - 27.wav, Score de Sentimento: 0.8971622586250305\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Arquivo: positivo - 3.wav, Score de Sentimento: 0.000303157459711656\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Arquivo: positivo - 4.wav, Score de Sentimento: 0.9999952912330627\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Arquivo: positivo - 5.wav, Score de Sentimento: 0.999999463558197\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Arquivo: positivo - 6.wav, Score de Sentimento: 6.542539722431684e-06\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Arquivo: positivo - 7.wav, Score de Sentimento: 0.9479096531867981\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Arquivo: positivo - 8.wav, Score de Sentimento: 0.5381019115447998\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Arquivo: positivo - 9.wav, Score de Sentimento: 3.294039561296813e-05\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "# Função para extrair características do áudio\n",
    "def extract_features(file_path):\n",
    "    y, sr = librosa.load(file_path)\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13), axis=1)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(y=y, sr=sr), axis=1)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y=y, sr=sr), axis=1)\n",
    "    features = np.hstack([mfccs, chroma, mel])\n",
    "    return features\n",
    "\n",
    "# Diretório contendo os arquivos de áudio\n",
    "audio_directory = 'audios classificados/'\n",
    "\n",
    "# Carregar o modelo treinado\n",
    "model = load_model(\"seu_modelo.h5\")\n",
    "\n",
    "# Loop pelos arquivos no diretório\n",
    "for filename in os.listdir(audio_directory):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        # Construir o caminho completo do arquivo\n",
    "        file_path = os.path.join(audio_directory, filename)\n",
    "\n",
    "        # Extrair características do áudio\n",
    "        audio_features = extract_features(file_path)\n",
    "\n",
    "        # Ajustar as características para corresponder à entrada do modelo\n",
    "        audio_features_input = np.array(audio_features).reshape(1, -1)\n",
    "\n",
    "        # Obter o score de sentimento usando o modelo treinado\n",
    "        sentiment_score = model.predict(audio_features_input)\n",
    "\n",
    "        # Exibir o resultado para cada arquivo\n",
    "        print(f\"Arquivo: {filename}, Score de Sentimento: {sentiment_score[0][0]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
